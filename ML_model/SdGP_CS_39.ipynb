{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "KjZLjz8Xs4VD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "#import pandas as pd\n",
        "import librosa\n",
        "from sklearn.model_selection import train_test_split\n",
        "#from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "#from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usN-W-vyQAWg",
        "outputId": "995ba854-42e4-4679-b609-09c3de28b9a2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main_directory = '/content/drive/MyDrive/TESS_changed'"
      ],
      "metadata": {
        "id": "mP_syb4_uZ1c"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data and extract features and labels\n",
        "#data = pd.read_csv(\"your_data.csv\")\n",
        "#X = data.drop(\"emotion\", axis=1).values\n",
        "#y = data[\"emotion\"].values\n",
        "\n",
        "X= []\n",
        "Y= []"
      ],
      "metadata": {
        "id": "PXQHQjy0Rh3G"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mapping between folder names and labels\n",
        "label_mapping = {\n",
        "    'angry': 0,\n",
        "    'disgust': 1,\n",
        "    'fear': 2,\n",
        "    'happy': 3,\n",
        "    'neutral': 4,\n",
        "    'pleasant_suprise': 5,\n",
        "    'sad': 6\n",
        "}"
      ],
      "metadata": {
        "id": "bJuQ17ozTPsm"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate through each subdirectory (each emotion)\n",
        "for folder_name in os.listdir(main_directory):\n",
        "    folder_path = os.path.join(main_directory, folder_name)\n",
        "\n",
        "    if os.path.isdir(folder_path):\n",
        "        label = label_mapping.get(folder_name, -1)  # -1 if folder name not found in the mapping\n",
        "        if label != -1:\n",
        "            # Iterate through each .wav file in the subdirectory\n",
        "            for filename in os.listdir(folder_path):\n",
        "                if filename.endswith(\".wav\"):\n",
        "                    # Load audio file using librosa\n",
        "                    audio_path = os.path.join(folder_path, filename)\n",
        "                    audio, _ = librosa.load(audio_path, sr=None)  # sr=None to preserve the original sampling rate\n",
        "\n",
        "                    # Extract Mel spectrogram\n",
        "                    mel_spec = librosa.feature.melspectrogram(y=audio, sr=_, n_mels=64)\n",
        "                    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
        "\n",
        "                    #mel_spec_db_fixed = librosa.util.fix_length(mel_spec_db, 9600, mode='constant', constant_values=0)\n",
        "\n",
        "                    mel_spec_db_fixed = librosa.util.fix_length(mel_spec_db, size=960)\n",
        "\n",
        "                    X.append(mel_spec_db_fixed)\n",
        "                    Y.append(label)\n",
        "\n",
        "#print(f\"Shape of X before flattening: {X.shape}\")\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "#X = np.array([x.flatten() for x in X])\n",
        "#Y = np.array(Y)\n",
        "\n",
        "\n",
        "# Expand dimensions for Conv2D input\n",
        "X = np.expand_dims(X, axis=-1)\n",
        "\n",
        "# Convert labels to categorical if using categorical_crossentropy as the loss\n",
        "# y = to_categorical(y)\n"
      ],
      "metadata": {
        "id": "6FODVBz8xFnV"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training and testing sets\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "zS6b060bAi1t"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''model = Sequential()\n",
        "\n",
        "# First convolutional block\n",
        "model.add(layers.Conv2D(filters=32, kernel_size=(3,3), activation=\"relu\", input_shape=(X_train.shape[1], X_train.shape[2], 1)))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "# Second convolutional block\n",
        "model.add(layers.Conv2D(filters=64, kernel_size=(3,3), activation=\"relu\"))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "# Flatten and feed into dense layers\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation=\"relu\"))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(7, activation=\"softmax\"))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])'''"
      ],
      "metadata": {
        "id": "DBoOKZ4oAnAC"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "# First convolutional block\n",
        "model.add(layers.Conv2D(filters=64, kernel_size=(3, 3), activation=\"relu\", input_shape=(X_train.shape[1], X_train.shape[2], 1)))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.BatchNormalization())\n",
        "\n",
        "# Second convolutional block\n",
        "model.add(layers.Conv2D(filters=128, kernel_size=(3, 3), activation=\"relu\"))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.BatchNormalization())\n",
        "\n",
        "# Flatten and feed into dense layers\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation=\"relu\"))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(7, activation=\"softmax\"))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=0.0001), metrics=[\"accuracy\", \"precision\", \"recall\", \"f1_score\"])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, Y_train, epochs=10, batch_size=32, validation_data=(X_test, Y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dMn4XZInyT1",
        "outputId": "2030ccfc-6612-4ebd-8c0a-bf989aa06c25"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "70/70 [==============================] - 700s 10s/step - loss: 3.3297 - accuracy: 0.5192 - val_loss: 1.3066 - val_accuracy: 0.5893\n",
            "Epoch 2/10\n",
            "70/70 [==============================] - 735s 11s/step - loss: 0.4351 - accuracy: 0.8290 - val_loss: 1.1367 - val_accuracy: 0.8054\n",
            "Epoch 3/10\n",
            "70/70 [==============================] - 734s 11s/step - loss: 0.2807 - accuracy: 0.8862 - val_loss: 0.6687 - val_accuracy: 0.9286\n",
            "Epoch 4/10\n",
            "70/70 [==============================] - 730s 10s/step - loss: 0.1931 - accuracy: 0.9201 - val_loss: 0.2670 - val_accuracy: 0.9857\n",
            "Epoch 5/10\n",
            "70/70 [==============================] - 690s 10s/step - loss: 0.1380 - accuracy: 0.9406 - val_loss: 0.1519 - val_accuracy: 0.9821\n",
            "Epoch 6/10\n",
            "70/70 [==============================] - 733s 10s/step - loss: 0.1110 - accuracy: 0.9531 - val_loss: 0.0399 - val_accuracy: 0.9929\n",
            "Epoch 7/10\n",
            "70/70 [==============================] - 727s 10s/step - loss: 0.0967 - accuracy: 0.9607 - val_loss: 0.0205 - val_accuracy: 0.9946\n",
            "Epoch 8/10\n",
            "70/70 [==============================] - 683s 10s/step - loss: 0.0764 - accuracy: 0.9696 - val_loss: 0.0239 - val_accuracy: 0.9911\n",
            "Epoch 9/10\n",
            "70/70 [==============================] - 681s 10s/step - loss: 0.0590 - accuracy: 0.9714 - val_loss: 0.0147 - val_accuracy: 0.9929\n",
            "Epoch 10/10\n",
            "70/70 [==============================] - 754s 11s/step - loss: 0.0566 - accuracy: 0.9781 - val_loss: 0.0228 - val_accuracy: 0.9929\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7845416d66e0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training history\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "JHXwBvsx3fPO",
        "outputId": "f4ac8aa9-e8ef-4b7f-c3be-ccc7276ca455"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'history' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-b81c3a696919>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Plot training history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lower right'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model in smaller batches\n",
        "'''batch_size = 32\n",
        "for epoch in range(100):\n",
        "    for start in range(0, len(X_train), batch_size):\n",
        "        end = start + batch_size\n",
        "        model.train_on_batch(X_train[start:end], Y_train[start:end])'''"
      ],
      "metadata": {
        "id": "4MRnxxVZkFaf"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model.fit(X_train, Y_train, epochs=10, batch_size=32, validation_data=(X_test, _test))\n"
      ],
      "metadata": {
        "id": "-tkhCrzXAqmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test, Y_test)\n",
        "print(\"Loss:\", loss)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "B57mXz4WAtGQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d55d91f-8ce9-44c8-d1b2-15bac12715da"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18/18 [==============================] - 42s 2s/step - loss: 0.0228 - accuracy: 0.9929\n",
            "Loss: 0.022754773497581482\n",
            "Accuracy: 0.9928571581840515\n"
          ]
        }
      ]
    }
  ]
}